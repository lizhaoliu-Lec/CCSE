_BASE_: "./Base-RCNN-FPN.yaml"
MODEL:
  # optimized weights to load
  # <========= the weights optimized by using print dataset ===========>
  #  WEIGHTS: /home/liulizhao/projects/DetectionBasedOnDetectron2/output/online_stroke_instance_debug_mask_rcnn/20210628.231643/model_final.pth
  # <========= the weights optimized by using online dataset ===========>
  # WEIGHTS: /home/liulizhao/projects/DetectionBasedOnDetectron2/output/stroke_instance_debug_mask_rcnn/20210614.012508/model_final.pth
  # WEIGHTS: output/mask_rcnn_R_50_FPN_3x_print_stroke_default/20210715.130012/model_0104999.pth
  ANCHOR_GENERATOR:
    # SIZES: [ [ 32 ], [ 64 ], [ 128 ], [ 256 ], [ 512 ] ] # default
    SIZES: [ [ 16 ], [ 32 ], [ 64 ], [ 128 ], [ 256 ] ]  # One size for each in feature map init
    # ASPECT_RATIOS: [ [ 0.5, 1.0, 2.0 ] ] # default
    ASPECT_RATIOS: [ [ 0.5, 1.0, 2.0, 4.0 ] ]  # Three aspect ratios (same for all in feature maps) init
  # WEIGHTS: output/mask_rcnn_R_50_FPN_3x_print_stroke_anchor_scale_init/20210715.130135/model_0214999.pth
  # WEIGHTS: output/mask_rcnn_R_50_FPN_3x_online_rbg_stroke_default/20210728.173620/model_0269999.pth
  # WEIGHTS: output/mask_rcnn_R_50_FPN_3x_online_rgb_stroke_anchor_scale_init/20210728.174547/model_0269999.pth
  # WEIGHTS: output/mask_rcnn_R_50_FPN_attention_3x_print_stroke_anchor_scale_init_sam/20210728.175643/model_0229999.pth
  # WEIGHTS: output/mask_rcnn_R_50_FPN_attention_3x_print_stroke_anchor_scale_init_nonlocal/20210728.175830/model_0234999.pth
  # WEIGHTS: output/mask_rcnn_R_50_FPN_3x_print_stroke_anchor_scale_init_relabeled/20210803.232822/model_0059999.pth
  # WEIGHTS: output/mask_rcnn_R_50_FPN_3x_print_stroke_anchor_scale_init_relabeled/20210803.232822/model_0244999.pth
  # WEIGHTS: output/mask_rcnn_R_50_FPN_3x_online_stroke_anchor_scale_init/20210715.132822/model_0264999.pth
  # WEIGHTS: output/mask_rcnn_R_50_FPN_3x_online_stroke_default/20210715.131820/model_0264999.pth
  # WEIGHTS: output/mask_rcnn_R_50_FPN_3x_online_stroke_default/20210715.131820/model_final.pth
  # WEIGHTS: output/mask_rcnn_R_50_FPN_3x_online_rgb_stroke_anchor_scale_init_bs16/20210719.235229/model_0259999.pth
  # WEIGHTS: output/mask_rcnn_R_50_FPN_3x_online_rbg_stroke_default_bs16/20210719.235139/model_0254999.pth
  # WEIGHTS: output/mask_rcnn_R_50_FPN_3x_print_stroke_anchor_scale_init_offline/20210809.175258/model_0219999.pth
  # WEIGHTS: output/mask_rcnn_R_50_FPN_3x_print_stroke_anchor_scale_init_relabeled_full/20210811.221530/model_0224999.pth
  # WEIGHTS: output/mask_rcnn_R_50_FPN_3x_print_stroke_anchor_scale_init_relabeled_full/20210811.221530/model_0029999.pth
  # WEIGHTS: output/mask_rcnn_R_50_FPN_3x_print_stroke_anchor_scale_init_print_and_offline/20210811.164013/model_0219999.pth
  WEIGHTS: output/mask_rcnn_R_50_FPN_3x_print_stroke_anchor_scale_init_offline_binary/20210812.204106/model_0219999.pth
  MASK_ON: True
  RESNETS:
    DEPTH: 50
  ROI_HEADS:
    # coco has 80 classes, but we only have 25 stroke classes
    NUM_CLASSES: 25 # default 80
DATALOADER:
  NUM_WORKERS: 8 # default 4, too slow
INPUT:
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 144
  MAX_SIZE_TRAIN: 144
  MIN_SIZE_TEST: 112
  MIN_SIZE_TRAIN: [112, 120]
DATASETS:
  # <========= handwritten dataset ===========>
  TRAIN: ("handwritten_stroke_2021_train",)
  TEST: ("handwritten_stroke_2021_val",)
  # <========= online dataset ===========>
  #  TRAIN: ("chinese_online_stroke_2021_train",)
  #  TEST: ("chinese_online_stroke_2021_val",)
# the following fields are additionally added to init the env, set output log, and register dataset...
GPU_IDS: [ 0 ] # env related fields
# OUTPUT_ID: mask_rcnn_R_50_FPN_3x_print_default_stroke_test # output log are other files related fields
# OUTPUT_ID: mask_rcnn_R_50_FPN_3x_print_stroke_anchor_scale_init_test # output log are other files related fields
# OUTPUT_ID: mask_rcnn_R_50_FPN_3x_online_stroke_anchor_scale_init_test # output log are other files related fields
# OUTPUT_ID: mask_rcnn_R_50_FPN_3x_online_stroke_default_test # output log are other files related fields
# OUTPUT_ID: mask_rcnn_R_50_FPN_3x_online_stroke_test # output log are other files related fields
# OUTPUT_ID: mask_rcnn_R_50_FPN_3x_online_rgb_stroke_anchor_scale_init_bs16_test # output log are other files related fields
# OUTPUT_ID: mask_rcnn_R_50_FPN_3x_online_rbg_stroke_default_bs16_test # output log are other files related fields
# OUTPUT_ID: mask_rcnn_R_50_FPN_3x_online_rbg_stroke_default_test
# OUTPUT_ID: mask_rcnn_R_50_FPN_3x_online_rgb_stroke_anchor_scale_init_test
# OUTPUT_ID: mask_rcnn_R_50_FPN_attention_3x_print_stroke_anchor_scale_init_sam_test
# OUTPUT_ID: mask_rcnn_R_50_FPN_attention_3x_print_stroke_anchor_scale_init_nonlocal_test
# OUTPUT_ID: mask_rcnn_R_50_FPN_attention_3x_print_stroke_anchor_scale_init_relabeled_test
# OUTPUT_ID: mask_rcnn_R_50_FPN_attention_3x_print_stroke_anchor_scale_init_offline_test
# OUTPUT_ID: mask_rcnn_R_50_FPN_3x_print_stroke_anchor_scale_init_relabeled_full_test
# OUTPUT_ID: mask_rcnn_R_50_FPN_3x_print_stroke_anchor_scale_init_print_and_offline_test
OUTPUT_ID: mask_rcnn_R_50_FPN_3x_print_stroke_anchor_scale_init_offline_binary_test
# dataset registration related fields
DATA_ROOT: /tmp/binary_handwritten_stroke_2021
DATASET_NAME: handwritten_stroke_2021
TRAIN_JSON_NAME: instances_test2021.json
VAL_JSON_NAME: instances_test2021.json
# <========= rgb test dataset ===========>
# TRAIN_IMAGE_DIR: test2021
# VAL_IMAGE_DIR: test2021
# <========= binary test dataset ===========>
TRAIN_IMAGE_DIR: binarytest2021
VAL_IMAGE_DIR: binarytest2021
VIS_DATASET_RESULT: true # whether to visualize the dataset results
NUM_VIS_PROPOSAL: 50 # number of proposal to visialize
# <========= put the path of any images you want to visualize here ===========>
IMAGE_PATHS: # default None, means not visualizing
  - 'resources/MotivationExpV2/chang.jpg'
  - 'resources/MotivationExpV2/chang-simple.jpg'
  - 'resources/MotivationExpV2/chun.jpg'
  - 'resources/MotivationExpV2/chun-simple.jpg'
  - 'resources/MotivationExpV2/jiang.jpg'
  - 'resources/MotivationExpV2/jiang-simple.jpg'
  - 'resources/MotivationExpV2/tong.jpg'
  - 'resources/MotivationExpV2/tong-simple.jpg'
#  - resources/inferenceImage/hard/mian-linmo.jpg
#  - resources/inferenceImage/hard/mian-shouxie.jpg
#  - resources/inferenceImage/hard/shu-linmo.jpg
#  - resources/inferenceImage/hard/shu-shouxie.jpg
#  - resources/inferenceImage/medium/jian-linmo.jpg
#  - resources/inferenceImage/medium/jian-shouxie.jpg
#  - resources/inferenceImage/medium/jian-yinshua.jpg
#  - resources/inferenceImage/medium/wen-linmo.jpg
#  - resources/inferenceImage/medium/wen-shouxie.jpg
#  - resources/inferenceImage/medium/wen-yinshua.jpg
#  - resources/inferenceImage/simple/san-linmo.jpg
#  - resources/inferenceImage/simple/san-shouxie.jpg
#  - resources/inferenceImage/simple/san-yinshua.jpg
#  - resources/inferenceImage/simple/yi-linmo.jpg
#  - resources/inferenceImage/simple/yi-shouxie.jpg
#  - resources/inferenceImage/simple/yi-yinshua.jpg
#  - resources/inferenceImage/whole.jpg
#  - resources/inferenceImage/dou.jpg
#  - resources/inferenceImage/dou1.jpg
#  - resources/inferenceImage/dou2.jpg
#  - resources/inferenceImage/dou_train_test.png